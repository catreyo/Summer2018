{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784)\n",
      "(55000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#Data processing for mnist\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "image_height = 28\n",
    "image_width = 28\n",
    " \n",
    "color_channels = 1\n",
    " \n",
    "model_name = \"mnist\"\n",
    " \n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    " \n",
    "train_data = mnist.train.images\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    " \n",
    "eval_data = mnist.test.images\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    " \n",
    "category_names = list(map(str, range(10)))\n",
    " \n",
    "# TODO: Process mnist data\n",
    "print(train_data.shape)\n",
    " \n",
    "train_data = np.reshape(train_data, (-1, image_height, image_width, color_channels))\n",
    " \n",
    "print(train_data.shape)\n",
    " \n",
    "eval_data = np.reshape(eval_data, (-1, image_height, image_width, color_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b6818c91a200>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mcifar_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./cifar-10-data/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Data processing for cifar-10\n",
    "\n",
    "image_height = 32\n",
    "image_width = 32\n",
    " \n",
    "color_channels = 3\n",
    " \n",
    "model_name = \"cifar\"\n",
    " \n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    " \n",
    "cifar_path = './cifar-10-data/'\n",
    " \n",
    "train_data = np.array([])\n",
    "train_labels = np.array([])\n",
    " \n",
    "# Load all the data batches.\n",
    "for i in range(1,6):\n",
    "    data_batch = unpickle(cifar_path + 'data_batch_' + str(i))\n",
    "    train_data = np.append(train_data, data_batch[b'data'])\n",
    "    train_labels = np.append(train_labels, data_batch[b'labels'])\n",
    " \n",
    " \n",
    "# Load the eval batch.\n",
    "eval_batch = unpickle(cifar_path + 'test_batch')\n",
    " \n",
    "eval_data = eval_batch[b'data']\n",
    "eval_labels = eval_batch[b'labels'] \n",
    " \n",
    "# Load the english category names.\n",
    "category_names_bytes = unpickle(cifar_path + 'batches.meta')[b'label_names']\n",
    "category_names = list(map(lambda x: x.decode(\"utf-8\"), category_names_bytes))\n",
    " \n",
    "# TODO: Process Cifar data\n",
    " \n",
    "def process_data(data):\n",
    "    float_data = np.array(data, dtype=float) / 255.0\n",
    "    \n",
    "    reshaped_data = np.reshape(float_data, (-1, color_channels, image_height, image_width))\n",
    "     \n",
    "    transposed_data = np.transpose(reshaped_data, [0, 2, 3, 1])\n",
    "    plt.imshow(transposed_data[0])\n",
    "     \n",
    "    reshaped_data = np.reshape(float_data, (-1, image_height, image_width, color_channels))\n",
    "    plt.imshow(reshaped_data[0])\n",
    "    \n",
    "    return transposed_data\n",
    " \n",
    " \n",
    "train_data = process_data(train_data)\n",
    " \n",
    "eval_data = process_data(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784)\n",
      "(55000, 28, 28, 1)\n",
      "(?, 32, 32, 3)\n",
      "(?, 32, 32, 32)\n",
      "(?, 16, 16, 32)\n",
      "(?, 32, 32, 54)\n",
      "(?, 16, 16, 32)\n",
      "(?, 1024)\n",
      "(?, 1024)\n",
      "(?, 10)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d7d978d9935c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0mbatch_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_operation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_labels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Data processing for mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "image_height = 28\n",
    "image_width = 28\n",
    " \n",
    "color_channels = 1\n",
    " \n",
    "model_name = \"mnist\"\n",
    " \n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    " \n",
    "train_data = mnist.train.images\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    " \n",
    "eval_data = mnist.test.images\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    " \n",
    "category_names = list(map(str, range(10)))\n",
    " \n",
    "# TODO: Process mnist data\n",
    "print(train_data.shape)\n",
    " \n",
    "train_data = np.reshape(train_data, (-1, image_height, image_width, color_channels))\n",
    " \n",
    "print(train_data.shape)\n",
    " \n",
    "eval_data = np.reshape(eval_data, (-1, image_height, image_width, color_channels))\n",
    "\n",
    "#Data processing for cifar-10\n",
    "\n",
    "image_height = 32\n",
    "image_width = 32\n",
    " \n",
    "color_channels = 3\n",
    " \n",
    "model_name = \"cifar\"\n",
    " \n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    " \n",
    "cifar_path = './cifar-10-data/'\n",
    " \n",
    "train_data = np.array([])\n",
    "train_labels = np.array([])\n",
    " \n",
    "# Load all the data batches.\n",
    "for i in range(1,6):\n",
    "    data_batch = unpickle(cifar_path + 'data_batch_' + str(i))\n",
    "    train_data = np.append(train_data, data_batch[b'data'])\n",
    "    train_labels = np.append(train_labels, data_batch[b'labels'])\n",
    " \n",
    "\n",
    "# Load the eval batch.\n",
    "eval_batch = unpickle(cifar_path + 'test_batch')\n",
    " \n",
    "eval_data = eval_batch[b'data']\n",
    "eval_labels = eval_batch[b'labels'] \n",
    " \n",
    "# Load the english category names.\n",
    "category_names_bytes = unpickle(cifar_path + 'batches.meta')[b'label_names']\n",
    "category_names = list(map(lambda x: x.decode(\"utf-8\"), category_names_bytes))\n",
    " \n",
    "# TODO: Process Cifar data\n",
    " \n",
    "def process_data(data):\n",
    "    float_data = np.array(data, dtype=float) / 255.0\n",
    "    \n",
    "    reshaped_data = np.reshape(float_data, (-1, color_channels, image_height, image_width))\n",
    "     \n",
    "    transposed_data = np.transpose(reshaped_data, [0, 2, 3, 1])\n",
    "    plt.imshow(transposed_data[0])\n",
    "     \n",
    "    reshaped_data = np.reshape(float_data, (-1, image_height, image_width, color_channels))\n",
    "    plt.imshow(reshaped_data[0])\n",
    "    \n",
    "    return transposed_data\n",
    "\n",
    "train_data = process_data(train_data) \n",
    "eval_data = process_data(eval_data)\n",
    "\n",
    "\n",
    "class ConvNet:\n",
    "     \n",
    "    def __init__(self, image_height, image_width, channels, num_classes):\n",
    "         \n",
    "        self.input_layer = tf.placeholder(dtype=tf.float32, shape=[None, image_height, image_width, channels], name=\"inputs\")\n",
    "        print(self.input_layer.shape)\n",
    "        \n",
    "        conv_layer_1 = tf.layers.conv2d(self.input_layer, filters = 32, kernel_size=[5,5], padding=\"same\", activation=tf.nn.relu)\n",
    "        print(conv_layer_1.shape)\n",
    "         \n",
    "        pooling_layer_1 = tf.layers.max_pooling2d(conv_layer_1, pool_size=[2,2], strides=2)\n",
    "        print(pooling_layer_1.shape)\n",
    "        \n",
    "        conv_layer_2 = tf.layers.conv2d(self.input_layer, filters = 54, kernel_size=[5,5], padding=\"same\", activation=tf.nn.relu)\n",
    "        print(conv_layer_2.shape)\n",
    "        \n",
    "        pooling_layer_2 = tf.layers.max_pooling2d(conv_layer_2, pool_size=[2,2], strides=2)\n",
    "        print(pooling_layer_1.shape)\n",
    "        \n",
    "        flattened_pooling = tf.layers.flatten(pooling_layer_2)\n",
    "        dense_layer = tf.layers.dense(flattened_pooling, 1024, activation=tf.nn.relu)\n",
    "        print(dense_layer.shape)\n",
    "        \n",
    "        dropout = tf.layers.dropout(dense_layer, rate=0.4, training=True)\n",
    "        print(dense_layer.shape)\n",
    "        \n",
    "        outputs = tf.layers.dense(dropout, num_classes)\n",
    "        print(outputs.shape)\n",
    "        \n",
    "        self.choice = tf.argmax(outputs, axis=1)\n",
    "        self.probability = tf.nn.softmax(outputs)\n",
    "        \n",
    "        self.labels = tf.placeholder(dtype=tf.float32, name=\"labels\")\n",
    "        self.accuracy, self.accuracy_op = tf.metrics.accuracy(self.labels, self.choice)\n",
    "         \n",
    "        one_hot_labels = tf.one_hot(indices=tf.cast(self.labels, dtype=tf.int32), depth=num_classes)     \n",
    "        self.loss = tf.losses.softmax_cross_entropy(onehot_labels=one_hot_labels, logits=outputs)\n",
    "         \n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-2)\n",
    "        self.train_operation = optimizer.minimize(loss=self.loss, global_step=tf.train.get_global_step())\n",
    "        \n",
    "training_steps = 20000\n",
    "batch_size = 64\n",
    " \n",
    "path = \"./\" + model_name + \"-cnn/\"\n",
    " \n",
    "load_checkpoint = False\n",
    "\n",
    "# TODO: implement the training loop\n",
    "tf.reset_default_graph()\n",
    " \n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "dataset = dataset.shuffle(buffer_size=train_labels.shape[0])\n",
    "dataset = dataset.batch(batch_size)\n",
    "dataset = dataset.repeat()\n",
    " \n",
    "dataset_iterator = dataset.make_initializable_iterator()\n",
    "next_element = dataset_iterator.get_next()\n",
    " \n",
    "cnn = ConvNet(image_height,image_width,color_channels,10)\n",
    " \n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    " \n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "     \n",
    "with tf.Session() as sess:\n",
    "     \n",
    "    if load_checkpoint:\n",
    "        checkpoint = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess, checkpoint.model_checkpoint_path)\n",
    "    else:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "     \n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(dataset_iterator.initializer)\n",
    "    for step in range(training_steps):\n",
    "        current_batch = sess.run(next_element)\n",
    "         \n",
    "        batch_inputs = current_batch[0]\n",
    "        batch_labels = current_batch[1]\n",
    "         \n",
    "        sess.run((cnn.train_operation, cnn.accuracy_op), feed_dict={ cnn.input_layer:batch_inputs, cnn.labels:batch_labels})\n",
    "        \n",
    "        if step % 1000 == 0 and step > 0:\n",
    "            current_acc = sess.run(cnn.accuracy)\n",
    "             \n",
    "            print(\"Accuracy at step \" + str(step) + \": \" + str(current_acc))\n",
    "            print(\"Saving checkpoint\")\n",
    "            saver.save(sess, path + model_name, step)\n",
    "         \n",
    "    print(\"Saving final checkpoint for training session.\")\n",
    "    saver.save(sess, path + model_name, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
